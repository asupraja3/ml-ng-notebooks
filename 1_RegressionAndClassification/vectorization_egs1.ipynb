{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPwZJfZvUn/h6vyUZ71twsX",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/asupraja3/ml-ng-notebooks/blob/main/vectorization_egs1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-o5KY_ppVnyr"
      },
      "outputs": [],
      "source": [
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Part 1: Python warm-up\n",
        "print(\"PART 1: Python Warm-Up\\n\")\n",
        "\n",
        "#x is an array here\n",
        "def sigmoid(x):\n",
        "  return 1 / (1 + np.exp(-x))\n",
        "\n",
        "x = np.array([1,2,3])\n",
        "print(\"Sigmoid of x:\", sigmoid(x))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NloqDMWCR9s6",
        "outputId": "4770e43b-36cd-41d4-ff2a-f8d0624cc167"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PART 1: Python Warm-Up\n",
            "\n",
            "Sigmoid of x: [0.73105858 0.88079708 0.95257413]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Part 2: Sigmoid Gradient\n",
        "print(\"\\nPART 2: Sigmoid Gradient\\n\")\n",
        "\n",
        "def sigmoid_derivative(x):\n",
        "    s = sigmoid(x)\n",
        "    return s * (1 - s)\n",
        "\n",
        "print(\"Sigmoid gradient:\", sigmoid_derivative(x))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d9bFw9B6SUxv",
        "outputId": "18868f12-e987-4cca-a3b9-2e6a3ac49c32"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "PART 2: Sigmoid Gradient\n",
            "\n",
            "Sigmoid gradient: [0.19661193 0.10499359 0.04517666]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Part 3: Reshaping arrays\n",
        "# In computer vision, we often flatten images before feeding them into algorithms\n",
        "#  (like logistic regression, fully connected layers in NN).\n",
        "print(\"\\nPART 3: Reshaping Arrays\\n\")\n",
        "\n",
        "def image2vector(image):\n",
        "  return image.reshape(-1,1)\n",
        "\n",
        "image = np.array([\n",
        "    [[0.678, 0.234, 0.293],\n",
        "     [0.907, 0.366, 0.456],\n",
        "     [0.123, 0.456, 0.789]]\n",
        "])\n",
        "v = image2vector(image)\n",
        "print(\"image2vector output shape:\", v.shape)\n",
        "print(v)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PA8bPhrQSYyi",
        "outputId": "c4395ad5-9960-4b27-9b7f-6861bcaf65ab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "PART 3: Reshaping Arrays\n",
            "\n",
            "image2vector output shape: (9, 1)\n",
            "[[0.678]\n",
            " [0.234]\n",
            " [0.293]\n",
            " [0.907]\n",
            " [0.366]\n",
            " [0.456]\n",
            " [0.123]\n",
            " [0.456]\n",
            " [0.789]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Part 4: Row-wise L2 normalization:meaning it scales each row in the matrix so that its\n",
        "#  L2 norm (Euclidean length) becomes 1.\n",
        "print(\"\\nPART 4: Row-wise L2 Normalization\\n\")\n",
        "\n",
        "def normalize_rows(x):\n",
        "    norm = np.linalg.norm(x, ord=2, axis=1, keepdims=True)\n",
        "    return x / norm\n",
        "\n",
        "x = np.array([[0, 3, 4], [1, 6, 4]])\n",
        "print(\"Normalized rows:\\n\", normalize_rows(x))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D11uyPRGSqDG",
        "outputId": "ed076fa5-d091-4721-f867-a415de1df53a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "PART 4: Row-wise L2 Normalization\n",
            "\n",
            "Normalized rows:\n",
            " [[0.         0.6        0.8       ]\n",
            " [0.13736056 0.82416338 0.54944226]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Part 5: Vectorized Dot Product:is showing the difference between dot product, outer product, and\n",
        "# element-wise multiplication in NumPy — all of which are vectorized operations you'll use a lot in ML.\n",
        "\n",
        "print(\"\\nPART 5: Dot Product and Outer Product\\n\")\n",
        "\n",
        "a = np.array([1.5, 2.0])\n",
        "b = np.array([4.0, 5.0])\n",
        "\n",
        "# Dot product\n",
        "dot = np.dot(a, b)\n",
        "# Outer product\n",
        "outer = np.outer(a, b)\n",
        "# Element-wise multiplication\n",
        "elementwise = np.multiply(a, b)\n",
        "\n",
        "print(\"Dot product:\", dot)\n",
        "print(\"Outer product:\\n\", outer)\n",
        "print(\"Element-wise multiplication:\", elementwise)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PDy15NEITDc3",
        "outputId": "457ee9ef-426f-4a35-a71e-f5922f5ad78b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "PART 5: Dot Product and Outer Product\n",
            "\n",
            "Dot product: 16.0\n",
            "Outer product:\n",
            " [[ 6.   7.5]\n",
            " [ 8.  10. ]]\n",
            "Element-wise multiplication: [ 6. 10.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Part 6: Loss Function Practice\n",
        "\n",
        "# This code is implementing two common loss functions in machine learning: L1 loss and L2 loss — used\n",
        "#  to measure the difference between predicted values (yhat) and actual values (y).\n",
        "print(\"\\nPART 6: Loss Function\\n\")\n",
        "def L1_loss(yhat, y):\n",
        "    return np.sum(np.abs(yhat - y))\n",
        "\n",
        "def L2_loss(yhat, y):\n",
        "    return np.sum((yhat - y) ** 2)\n",
        "\n",
        "yhat = np.array([0.9, 0.2, 0.1, 0.4, 0.9])\n",
        "y    = np.array([1,   0,   0,   1,   1])\n",
        "\n",
        "print(\"L1 loss:\", L1_loss(yhat, y))\n",
        "print(\"L2 loss:\", L2_loss(yhat, y))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d7fl0YggT0_M",
        "outputId": "bd34fdeb-3cb3-4c3c-e8b0-e8c928ce7d1d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "PART 6: Loss Function\n",
            "\n",
            "L1 loss: 1.1\n",
            "L2 loss: 0.43\n"
          ]
        }
      ]
    }
  ]
}